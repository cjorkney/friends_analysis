---
title: "Friends Analysis Report"
author: "Callum Orkney"
date: "13/12/2020"
output: github_document
---

``` {r packages, echo = FALSE, message = FALSE}
library(tidytuesdayR)
library(dplyr)
library(forcats)
library(tidytext)
library(stringr)
library(ggplot2)
library(RcppRoll)
library(purrr)
```


``` {r setup, echo = FALSE, message = FALSE}
# Set constants

names_six <- c('Monica Geller', 'Joey Tribbiani', 'Chandler Bing',
               'Phoebe Buffay', 'Ross Geller', 'Rachel Green')

movav_eps <- 30

# Get data

tuesdata <- tidytuesdayR::tt_load('2020-09-08')

lines <- tuesdata$friends
info <- tuesdata$friends_info
emotions <- tuesdata$friends_emotions

# Custom stopwords
stop_words_plus <- stop_words %>%
  rbind(
    tibble(
      word = c('yeah', 'hey', 'um', 'uh', 'ah', 'umm',
               "y'know", 'ya', 'ohh', 'gonna', 'wanna',
               'ross', 'rachel', 'monica', 'chandler', 'joey',
               'phoebe', 'huh', 'ooh', 'uhm', 'wow', 'woah', 'whoa',
               'guys', 'god', 'fine', 'gotta', 'pheebs', 'rach'),
      lexicon = 'custom'
    )
  )

# Clean up lines data

lines_clean <- lines %>%
  filter(!(speaker == 'Scene Directions')) %>%
  mutate(
    speaker = as_factor(speaker),
    ep_id = paste(season, episode, sep = '-'),
    ep_id = factor(ep_id, levels = unique(ep_id)),
    ep_no = cummax(as.numeric(ep_id)),
    line_id = paste(season, episode, scene, utterance, sep = '-')
    )

# Theme for sentiment bar chart
theme_sent_bar <- theme(
  panel.background = element_blank(),
  panel.grid.major.y = element_line(colour = "lightgrey"),
  axis.line = element_line(colour = "black")
)

```

## Analysis of number of lines
Summarising the data by episode and character, we can see how the number of lines per episode for each character has changed over time. To avoid an unreadable mess, let's calculate a 30-episode moving average:

``` {r lines-by-character}
lines_by_character <- lines_clean %>%
  filter(speaker %in% names_six) %>%
  group_by(ep_id, ep_no, speaker) %>% 
  summarise(lines = n()) %>%
  ungroup() %>% 
  group_by(speaker) %>%
  mutate(movav = roll_meanr(lines, movav_eps)) %>%
  ungroup()
```

Let's plot a line graph of this, with one line representing each character's moving average lines-per-episode over time:

``` {r line-plot, echo = FALSE, warning = FALSE}
ggplot(lines_by_character, aes(x = ep_no, y = movav, colour = speaker)) +
  geom_line() +
  labs(
    title = 'Number of lines per episode by main character',
    subtitle = paste0(movav_eps, '-episode moving averages'),
    x = 'Episode number', y = 'Lines spoken per episode',
    colour = 'Character'
  )
```

It looks like there's some significant change over time for some characters, and the trend overall appears to be an upward one. There also seems to be a more even distribution of lines among the characters towards the end of the show. So we can deduce from this plot that episodes contained more lines (although not necessarily more words!) near the end of the show's run than at its beginning. Note that, if we assume around 30 episodes per season, we can roughly take the starts of these lines as season 1 averages and the ends as season 10 averages.

It's a little hard to distinguish the series for each character, though. Let's create a faceted version of this plot so that we can see the changes for each character more clearly:

``` {r line-plot-facet-prep, echo = FALSE, warning = FALSE}

# Take first (movav) and last episodes from lines_by_character, to use as points and labels

lines_first <- lines_by_character %>%
  filter(ep_no == movav_eps)

lines_last <- lines_by_character %>%
  group_by(speaker) %>%
  slice(max(ep_no)) %>%
  ungroup()

# Define partially-filled versions of geom_point and geom_text to reduce
# duplicated code in labelling the end-points of the faceted plot

geom_point_movav_labels <- partial(geom_point,
                                   aes(x = ep_no, y = movav),
                                   shape = 21,
                                   fill = 'black',
                                   show.legend = FALSE)

geom_text_movav_labels <- partial(geom_text,
                                  aes(x = ep_no, y = movav,
                                      label = sprintf('%0.1f', round(movav, 1))),
                                  colour = 'black')
```

``` {r line-plot-facet, echo = FALSE, warning = FALSE}
ggplot(lines_by_character, aes(x = ep_no, y = movav, colour = speaker)) +
  geom_line(show.legend = FALSE, size = 1) +
  geom_point_movav_labels(data = lines_first) +
  geom_text_movav_labels(data = lines_first,
                         hjust = 0.8, vjust = -0.5) +
  geom_point_movav_labels(data = lines_last) +
  geom_text_movav_labels(data = lines_last,
                         hjust = -0.01, vjust = -0.5) +
  geom_line(aes(y = lines), alpha = 0.4, show.legend = FALSE) +
  coord_cartesian(xlim = c(0, 260), ylim = c(0, 80)) +
  facet_wrap(~ speaker) +
  labs(
    title = 'Number of lines per episode by main character - faceted',
    subtitle = paste0(movav_eps, '-episode moving averages'),
    x = 'Episode number', y = 'Lines spoken per episode',
    colour = 'Character'
  )
```

We can see more clearly now that the average number of lines spoken per episode was higher at the end of the show than at the start for all characters, and that Joey and Phoebe saw the most significant increases. Though all characters fluctuated over time (the time series for individual episodes have been added here with higher transparancy), these two had significantly fewer lines per episode in the first season than the other main characters. This may reflect Joey and Phoebe's early status as "light relief" characters that didn't drive the main plot points or romantic storylines - from my (possibly inaccurate) memory, those things were more the domain of Monica, Ross and Rachel in those days. I don't remember Chandler driving much of the early plot either, but I suppose his role as "the funny one" gave him a lot of lines.

## Sentiment analysis: best/worst episodes for each character
Let's tokenise the lines into words and do some sentiment analysis. I want to look at the net sentiment of words spoken by each character in each episode, and use that to decide which episodes were "best" and "worst" for each character. For each character, the episode with the highest net sentiment (using valences from the AFINN list) will be deemed their best (most positive) episode, while that with the lowest will be deemed their worst (most negative). Will the answers make sense?

``` {r best-worst-prep, message = FALSE, warning = FALSE}

# Tokenise lines to words, and clean

words_full <- lines_clean %>%
  unnest_tokens(output = word, input = text)

words_neat <- words_full %>%
  anti_join(stop_words_plus)

# Sentiments by character and episode
sents_ep_afinn <- words_neat %>%
  filter(speaker %in% names_six) %>% 
  inner_join(get_sentiments("afinn")) %>% 
  group_by(ep_no, season, episode, speaker) %>%
  summarise(net_sentiment = sum(value)) %>%
  ungroup()

# Best and worst episodes by character (based on net sentiment)

best_eps <- sents_ep_afinn %>% 
  group_by(speaker) %>%
  slice_max(net_sentiment) %>%
  slice_head() %>%
  left_join(select(info,
                   season, episode, title)
            , by = c("season", "episode"))

worst_eps <- sents_ep_afinn %>% 
  group_by(speaker) %>%
  slice_min(net_sentiment) %>%
  slice_head() %>%
  left_join(select(info,
                   season, episode, title)
            , by = c("season", "episode"))

best_worst_eps <- rbind(best_eps, worst_eps)

```

Here are the net sentiments of those episodes on a bar plot:

``` {r best-worst-plot, echo = FALSE, warning = FALSE}
ggplot(best_worst_eps, aes(x = speaker, y = net_sentiment, fill = speaker)) +
  geom_col(position = position_dodge2(), show.legend = FALSE) +
  geom_hline(yintercept = 0) +
  coord_flip() +
  geom_text(data = best_eps, aes(label = title, colour = speaker), show.legend = FALSE,
            hjust = "outward", position = position_nudge(x = -0.2, y = 1)) +
  geom_text(data = worst_eps, aes(label = title, colour = speaker), show.legend = FALSE,
            hjust = "outward", position = position_nudge(x = 0.25, y = -1)) +
  scale_y_continuous(limits = c(-200, 200)) +
  labs(title = "Best and worst episodes for each main character",
       subtitle = "Based on highest and lowest net AFINN sentiment of words spoken",
       x = NULL,
       y = "Net AFINN sentiment"
  ) +
  theme_sent_bar
```

Some of these feel right intuitively: *The One with Joey's Award* is the most positive episode for Joey, which doesn't seem unreasonable; it's also the best for Rachel, which I could believe too as they attend the ceremony together and are both excited about it (I think that's right, though I haven't watched it in a long time). Conversely, *The One Where Joey Loses His Insurance* sounds like it would be a low point for Joey, even for someone who's never seen Friends, so that makes sense too.

Some of the other episodes make sense too with a little memory of what happens in them, while others would need some looking into to work out.

Note that I've removed stopwords in this process - I'm not sure whether that's advisable for sentiment analysis, as it's more than possible that I've decided to remove some words that would've contributed to some of the sentiment scores.

## Things to do:
### Lines per character represented by distributions/boxplots
### Can we predict ratings based on lines spoken by each character? (Linear/RF regression)
### Break lines down into words (tidytext) and do some NLP - n-grams (popular 3/4-word phrases for each character?) / wordclouds / top words / topic modelling?




